{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c261d98c-8bc7-4ee2-b807-1179a87e405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 包引入\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.data import Data, Batch\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc8da1f4-41ab-4d9d-82d8-cf39f85843c7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/pm/codebert-base. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: /home/pm/codebert-base...\n",
      "Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d56b15a16e744ddc8975e4e839d3fa8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[-0.42088693380355835,\n",
       " 0.10436536371707916,\n",
       " 0.34373658895492554,\n",
       " 0.17476998269557953,\n",
       " -0.37004709243774414,\n",
       " -0.37455976009368896,\n",
       " -0.10668481886386871,\n",
       " 0.2982756793498993,\n",
       " 0.21411190927028656,\n",
       " 0.4020977020263672,\n",
       " -0.23685309290885925,\n",
       " 0.9128382205963135,\n",
       " -0.24038444459438324,\n",
       " -0.41095271706581116,\n",
       " 0.6471357941627502,\n",
       " 0.193195179104805,\n",
       " 0.24080625176429749,\n",
       " 0.24315451085567474,\n",
       " 0.05634622275829315,\n",
       " -0.03447640687227249,\n",
       " -0.1707223802804947,\n",
       " -0.2952006459236145,\n",
       " 0.5728013515472412,\n",
       " -0.6531931161880493,\n",
       " 0.3403095006942749,\n",
       " 0.39701181650161743,\n",
       " 0.1650542914867401,\n",
       " 0.8826589584350586,\n",
       " -0.32314327359199524,\n",
       " 1.038062334060669,\n",
       " -0.11942604929208755,\n",
       " 0.07969006896018982,\n",
       " 1.663250207901001,\n",
       " -0.003997768275439739,\n",
       " 0.29241180419921875,\n",
       " -0.2689550518989563,\n",
       " -0.46726828813552856,\n",
       " 0.2886401414871216,\n",
       " -0.00737615255638957,\n",
       " -0.46086862683296204,\n",
       " -0.2871817946434021,\n",
       " 0.9313816428184509,\n",
       " -1.048900842666626,\n",
       " 0.04647719860076904,\n",
       " 0.5819157361984253,\n",
       " 0.37019044160842896,\n",
       " 0.4209534227848053,\n",
       " -0.21951550245285034,\n",
       " -0.044514380395412445,\n",
       " 0.5246948599815369,\n",
       " 0.46653908491134644,\n",
       " 0.21462351083755493,\n",
       " -0.7390503287315369,\n",
       " -0.13495762646198273,\n",
       " 0.24562238156795502,\n",
       " 0.508459210395813,\n",
       " -1.0978177785873413,\n",
       " -0.33805128931999207,\n",
       " -0.28790441155433655,\n",
       " -0.2745429575443268,\n",
       " -0.15905031561851501,\n",
       " -0.11126881092786789,\n",
       " -0.20481377840042114,\n",
       " -0.4131791293621063,\n",
       " 1.5809035301208496,\n",
       " 0.3980380892753601,\n",
       " 0.6048609614372253,\n",
       " 0.8774890899658203,\n",
       " -0.07717643678188324,\n",
       " 0.0005532732466235757,\n",
       " -0.3230760991573334,\n",
       " -0.6593376994132996,\n",
       " -0.15029999613761902,\n",
       " -0.7243513464927673,\n",
       " -0.5606381893157959,\n",
       " 0.7376339435577393,\n",
       " -0.51949542760849,\n",
       " -7.371204853057861,\n",
       " 0.1761222630739212,\n",
       " 0.6603269577026367,\n",
       " 0.35233691334724426,\n",
       " -0.5613990426063538,\n",
       " 1.9370534420013428,\n",
       " 0.557449221611023,\n",
       " -0.5722782015800476,\n",
       " 0.006262741982936859,\n",
       " -0.2107572704553604,\n",
       " 0.2877877354621887,\n",
       " -0.6228615641593933,\n",
       " -0.044743895530700684,\n",
       " 0.25506237149238586,\n",
       " 0.16346392035484314,\n",
       " 0.8101486563682556,\n",
       " 0.6089169383049011,\n",
       " -0.181084543466568,\n",
       " 0.7070912718772888,\n",
       " 0.7392327189445496,\n",
       " -0.6444962024688721,\n",
       " 0.32307273149490356,\n",
       " -0.34266456961631775,\n",
       " -0.05792494863271713,\n",
       " -0.6070889830589294,\n",
       " 0.5229813456535339,\n",
       " 0.3336380422115326,\n",
       " 0.42134034633636475,\n",
       " -0.6414142847061157,\n",
       " 0.6596472859382629,\n",
       " -0.7487687468528748,\n",
       " 0.29429516196250916,\n",
       " -0.16195259988307953,\n",
       " 0.07678841799497604,\n",
       " -0.5624473094940186,\n",
       " 0.5973319411277771,\n",
       " 0.30561214685440063,\n",
       " 0.2153051495552063,\n",
       " -0.5365679264068604,\n",
       " 0.3949322998523712,\n",
       " 0.10093037039041519,\n",
       " 0.11828652024269104,\n",
       " -0.025797827169299126,\n",
       " -0.9057837724685669,\n",
       " 0.4502493739128113,\n",
       " -0.39423510432243347,\n",
       " 0.7525514364242554,\n",
       " -0.2233741134405136,\n",
       " 0.3997085392475128,\n",
       " -0.23275430500507355,\n",
       " -0.1249845027923584,\n",
       " 0.23622216284275055,\n",
       " 0.35602664947509766,\n",
       " -1.0967458486557007,\n",
       " -0.337621808052063,\n",
       " -0.40455085039138794,\n",
       " 0.6683667898178101,\n",
       " 0.5038952231407166,\n",
       " -0.34789228439331055,\n",
       " 0.4834473431110382,\n",
       " 0.11248011142015457,\n",
       " -0.5692949891090393,\n",
       " 0.42581361532211304,\n",
       " -0.5987570285797119,\n",
       " -0.38326823711395264,\n",
       " -0.0682537630200386,\n",
       " 0.3140803873538971,\n",
       " 0.5386616587638855,\n",
       " 0.07287541776895523,\n",
       " 0.05939169228076935,\n",
       " 0.5166760087013245,\n",
       " 0.2453291267156601,\n",
       " -0.42769575119018555,\n",
       " -0.7456804513931274,\n",
       " -0.1249982938170433,\n",
       " 1.5007092952728271,\n",
       " -0.2902391850948334,\n",
       " 0.1315075159072876,\n",
       " -2.325246810913086,\n",
       " -0.06539590656757355,\n",
       " 0.22553499042987823,\n",
       " 0.2858825922012329,\n",
       " -0.4988819360733032,\n",
       " 0.3035421073436737,\n",
       " -0.058437760919332504,\n",
       " -0.09727506339550018,\n",
       " 0.5597254633903503,\n",
       " 0.7080294489860535,\n",
       " 0.28073933720588684,\n",
       " -0.26179221272468567,\n",
       " -0.2764517664909363,\n",
       " 0.07230136543512344,\n",
       " 1.1398838758468628,\n",
       " -0.6552088260650635,\n",
       " -0.5974550843238831,\n",
       " -0.6394004821777344,\n",
       " 0.22398291528224945,\n",
       " 0.30890193581581116,\n",
       " 0.7901611924171448,\n",
       " 0.45936429500579834,\n",
       " -0.4207490384578705,\n",
       " -0.4907393157482147,\n",
       " 1.3322347402572632,\n",
       " 0.2629464864730835,\n",
       " -0.14904530346393585,\n",
       " 0.20168553292751312,\n",
       " -0.5524427890777588,\n",
       " -0.4321718215942383,\n",
       " 0.4340094029903412,\n",
       " -0.498293936252594,\n",
       " 0.6516914963722229,\n",
       " -0.10304555296897888,\n",
       " -0.2637740671634674,\n",
       " -0.3042687773704529,\n",
       " -0.2243935912847519,\n",
       " 0.4336690604686737,\n",
       " 0.5608900785446167,\n",
       " -0.005962039344012737,\n",
       " 0.364446222782135,\n",
       " -0.01842101290822029,\n",
       " 0.42365801334381104,\n",
       " 1.0922248363494873,\n",
       " 0.09497366845607758,\n",
       " -0.1434360146522522,\n",
       " 0.688556432723999,\n",
       " 0.5028002262115479,\n",
       " 0.45715200901031494,\n",
       " -0.07915861159563065,\n",
       " 0.15672548115253448,\n",
       " -0.5437666773796082,\n",
       " 0.6442177295684814,\n",
       " 0.41659048199653625,\n",
       " 1.374772310256958,\n",
       " 1.8512598276138306,\n",
       " 0.24302099645137787,\n",
       " 0.08467026054859161,\n",
       " -0.31001171469688416,\n",
       " -1.0593000650405884,\n",
       " 0.17258551716804504,\n",
       " -0.6789413690567017,\n",
       " -1.3553738594055176,\n",
       " -0.41383644938468933,\n",
       " -0.6343575716018677,\n",
       " -1.5728740692138672,\n",
       " 0.08002904802560806,\n",
       " -0.22029192745685577,\n",
       " -0.1404249519109726,\n",
       " -0.0381440594792366,\n",
       " 0.13378745317459106,\n",
       " 0.2705540359020233,\n",
       " -0.19256693124771118,\n",
       " -0.3478285074234009,\n",
       " 0.37703970074653625,\n",
       " -0.4458007514476776,\n",
       " -0.25581228733062744,\n",
       " -0.8833659291267395,\n",
       " -0.10391019284725189,\n",
       " -0.05124419555068016,\n",
       " -0.2832549512386322,\n",
       " -0.5543924570083618,\n",
       " 0.4203624725341797,\n",
       " 0.36332082748413086,\n",
       " -0.9653927087783813,\n",
       " -0.26286131143569946,\n",
       " 0.266888290643692,\n",
       " 0.4591004252433777,\n",
       " 0.9264715909957886,\n",
       " 0.1652449071407318,\n",
       " -0.5700095295906067,\n",
       " 0.251804381608963,\n",
       " 0.5856481194496155,\n",
       " 0.6631467342376709,\n",
       " 0.6870591044425964,\n",
       " 0.2341093271970749,\n",
       " 0.08313731849193573,\n",
       " 0.1766810417175293,\n",
       " -0.25255078077316284,\n",
       " 0.11957531422376633,\n",
       " -0.33223336935043335,\n",
       " -0.2453092783689499,\n",
       " -0.40978941321372986,\n",
       " 0.6946303248405457,\n",
       " 1.896477460861206,\n",
       " 0.3625330626964569,\n",
       " 0.12328562140464783,\n",
       " 0.6721081137657166,\n",
       " -0.614749550819397,\n",
       " 0.519408643245697,\n",
       " -0.06982579827308655,\n",
       " 0.371116042137146,\n",
       " 0.12955869734287262,\n",
       " 0.6152752041816711,\n",
       " 0.6659220457077026,\n",
       " 1.5547411441802979,\n",
       " 0.34852665662765503,\n",
       " -0.3657403290271759,\n",
       " 0.4179667830467224,\n",
       " 0.2593861222267151,\n",
       " 0.10849443078041077,\n",
       " 0.4813302159309387,\n",
       " 0.17234013974666595,\n",
       " -0.7472789287567139,\n",
       " -0.3865908980369568,\n",
       " -0.28417444229125977,\n",
       " -0.1575094312429428,\n",
       " 0.15192002058029175,\n",
       " -0.19270214438438416,\n",
       " -0.16232949495315552,\n",
       " -0.2622218728065491,\n",
       " 0.09528621286153793,\n",
       " 0.42702561616897583,\n",
       " 0.016955725848674774,\n",
       " -0.251973420381546,\n",
       " 0.3880620300769806,\n",
       " -0.6361058950424194,\n",
       " 1.2155870199203491,\n",
       " 0.046138983219861984,\n",
       " -0.18281690776348114,\n",
       " 0.20227797329425812,\n",
       " 0.37016743421554565,\n",
       " 0.5625694990158081,\n",
       " 0.41526684165000916,\n",
       " -0.4879011809825897,\n",
       " 0.36207449436187744,\n",
       " 0.3366983234882355,\n",
       " -0.3228308856487274,\n",
       " 0.31663912534713745,\n",
       " -0.36258581280708313,\n",
       " -0.3196396827697754,\n",
       " -0.49164560437202454,\n",
       " 0.52128005027771,\n",
       " 0.17388398945331573,\n",
       " -0.04331175237894058,\n",
       " 0.29119443893432617,\n",
       " -0.8693730235099792,\n",
       " -0.1851840615272522,\n",
       " -0.2761523127555847,\n",
       " 0.34699904918670654,\n",
       " -0.35518261790275574,\n",
       " -0.07467241585254669,\n",
       " 0.5610526204109192,\n",
       " -0.2955959141254425,\n",
       " 0.44895365834236145,\n",
       " 0.4746454358100891,\n",
       " -0.3238605260848999,\n",
       " 1.1078190803527832,\n",
       " -0.9743176698684692,\n",
       " 0.6631899476051331,\n",
       " 0.946875810623169,\n",
       " -0.8739290833473206,\n",
       " -0.7313830256462097,\n",
       " -1.5523946285247803,\n",
       " -0.1041807308793068,\n",
       " -0.9191251993179321,\n",
       " 0.8590854406356812,\n",
       " 0.5201324224472046,\n",
       " 1.7257616519927979,\n",
       " -0.8990434408187866,\n",
       " -0.4952250123023987,\n",
       " 0.5149908065795898,\n",
       " -0.38962242007255554,\n",
       " 0.24532979726791382,\n",
       " -0.511851966381073,\n",
       " -1.0629899501800537,\n",
       " 0.7485260367393494,\n",
       " 0.345338374376297,\n",
       " -0.37056875228881836,\n",
       " 0.21287712454795837,\n",
       " 1.0217421054840088,\n",
       " -0.3730022609233856,\n",
       " -0.014717912301421165,\n",
       " 1.4461781978607178,\n",
       " 0.3029272258281708,\n",
       " -0.8608408570289612,\n",
       " -0.8060376644134521,\n",
       " -0.33374229073524475,\n",
       " -0.40619564056396484,\n",
       " 0.23859649896621704,\n",
       " 1.8844859600067139,\n",
       " 0.4505704343318939,\n",
       " 0.15398524701595306,\n",
       " 0.01152948010712862,\n",
       " -0.04137321561574936,\n",
       " 0.18279024958610535,\n",
       " -0.368073046207428,\n",
       " 0.44043540954589844,\n",
       " 2.201756000518799,\n",
       " 0.8639392852783203,\n",
       " -0.057642862200737,\n",
       " -0.9039688110351562,\n",
       " 0.22152218222618103,\n",
       " -0.1094425618648529,\n",
       " 0.5383118391036987,\n",
       " -0.1302049160003662,\n",
       " -0.2909855544567108,\n",
       " 0.14260253310203552,\n",
       " 0.4785611033439636,\n",
       " 0.5363191962242126,\n",
       " -0.11762358248233795,\n",
       " 0.43746218085289,\n",
       " -0.3222683370113373,\n",
       " 0.22173179686069489,\n",
       " 0.062463779002428055,\n",
       " -0.7194193601608276,\n",
       " 0.3975944519042969,\n",
       " 0.32875096797943115,\n",
       " -0.02716187573969364,\n",
       " 0.46392250061035156,\n",
       " -1.9103634357452393,\n",
       " 0.4483639895915985,\n",
       " -0.26934316754341125,\n",
       " 1.355225920677185,\n",
       " -0.13434720039367676,\n",
       " 0.18218994140625,\n",
       " 0.16302324831485748,\n",
       " 0.38099539279937744,\n",
       " -0.466003954410553,\n",
       " -0.1786959171295166,\n",
       " 0.314574271440506,\n",
       " 0.21112275123596191,\n",
       " 0.3939419984817505,\n",
       " -0.38272878527641296,\n",
       " -0.466888427734375,\n",
       " -0.5720115303993225,\n",
       " 0.1710202991962433,\n",
       " -0.002236117608845234,\n",
       " 0.2892138659954071,\n",
       " -0.1448400616645813,\n",
       " -0.10345418006181717,\n",
       " -0.2419208139181137,\n",
       " -0.14619173109531403,\n",
       " -0.2653323709964752,\n",
       " 1.1478369235992432,\n",
       " -0.7072182893753052,\n",
       " 1.7199733257293701,\n",
       " -0.369357168674469,\n",
       " 0.15658998489379883,\n",
       " -0.16847676038742065,\n",
       " 0.33233463764190674,\n",
       " 0.5149129629135132,\n",
       " -0.7786359786987305,\n",
       " 0.19533418118953705,\n",
       " 0.45331433415412903,\n",
       " 0.35096976161003113,\n",
       " 0.21039427816867828,\n",
       " 0.5103862285614014,\n",
       " -0.3239297568798065,\n",
       " 0.5609050393104553,\n",
       " -0.10104727745056152,\n",
       " 0.18161191046237946,\n",
       " 0.07154429703950882,\n",
       " -0.42583563923835754,\n",
       " -0.3847096562385559,\n",
       " -0.4409802556037903,\n",
       " 0.04822003096342087,\n",
       " 0.02223050221800804,\n",
       " 0.20318621397018433,\n",
       " -0.7541815042495728,\n",
       " -0.4592011868953705,\n",
       " -0.49370816349983215,\n",
       " -0.16811783611774445,\n",
       " 0.4692363142967224,\n",
       " 0.5189869999885559,\n",
       " 0.48473310470581055,\n",
       " 0.35868608951568604,\n",
       " 0.3634178042411804,\n",
       " 0.36415818333625793,\n",
       " -0.07892337441444397,\n",
       " 0.4706379175186157,\n",
       " -0.3929198980331421,\n",
       " 1.445237398147583,\n",
       " 0.7487979531288147,\n",
       " -0.4003598093986511,\n",
       " 0.2880198359489441,\n",
       " 0.3037950396537781,\n",
       " 0.23592700064182281,\n",
       " -0.5344963669776917,\n",
       " 0.5026888251304626,\n",
       " -0.7892140746116638,\n",
       " 0.1031554564833641,\n",
       " -0.15001843869686127,\n",
       " 0.5082110166549683,\n",
       " 0.5779514908790588,\n",
       " -0.12152478098869324,\n",
       " 0.23279613256454468,\n",
       " 0.3976985514163971,\n",
       " -0.24313174188137054,\n",
       " 0.17668086290359497,\n",
       " -1.5220434665679932,\n",
       " 0.6398260593414307,\n",
       " -0.4475689232349396,\n",
       " 0.26615697145462036,\n",
       " 0.13823302090168,\n",
       " -0.9830499887466431,\n",
       " 0.16219307482242584,\n",
       " -0.41705402731895447,\n",
       " -0.43055951595306396,\n",
       " -0.4148278832435608,\n",
       " 0.04786771163344383,\n",
       " -0.4692395329475403,\n",
       " 1.662392497062683,\n",
       " 0.4475463628768921,\n",
       " 1.6782599687576294,\n",
       " -0.07366662472486496,\n",
       " -0.41928598284721375,\n",
       " -0.29290369153022766,\n",
       " -0.7221028208732605,\n",
       " 0.5871702432632446,\n",
       " 0.39016053080558777,\n",
       " -0.12082363665103912,\n",
       " -0.5804793238639832,\n",
       " -0.09879317879676819,\n",
       " -0.43937069177627563,\n",
       " -0.5474932193756104,\n",
       " -0.2639852464199066,\n",
       " -0.3869456946849823,\n",
       " 0.6713585257530212,\n",
       " -0.5664912462234497,\n",
       " 0.04421642795205116,\n",
       " 0.5160372257232666,\n",
       " 0.7904135584831238,\n",
       " -0.39111170172691345,\n",
       " 0.6969963908195496,\n",
       " 0.009090429171919823,\n",
       " 0.22559426724910736,\n",
       " 0.32696202397346497,\n",
       " 1.4394190311431885,\n",
       " -0.16318842768669128,\n",
       " 0.31705090403556824,\n",
       " -0.46004897356033325,\n",
       " 1.0115412473678589,\n",
       " 0.3662034273147583,\n",
       " 0.015055119059979916,\n",
       " -0.21439114212989807,\n",
       " 0.6798173189163208,\n",
       " 0.8406860828399658,\n",
       " 0.05457616597414017,\n",
       " -0.09191100299358368,\n",
       " 0.3401877284049988,\n",
       " -0.5413010120391846,\n",
       " -0.6615798473358154,\n",
       " -0.593532145023346,\n",
       " 2.2437782287597656,\n",
       " 0.679300844669342,\n",
       " 0.18568508327007294,\n",
       " -0.3043910264968872,\n",
       " 0.11738444119691849,\n",
       " 1.5344579219818115,\n",
       " -0.2173861414194107,\n",
       " -1.0348917245864868,\n",
       " -0.8595690131187439,\n",
       " -0.16034337878227234,\n",
       " -0.6200819611549377,\n",
       " -0.4402981400489807,\n",
       " -0.0032939554657787085,\n",
       " 0.39630940556526184,\n",
       " -0.008080204017460346,\n",
       " 0.3758397102355957,\n",
       " -0.29919856786727905,\n",
       " -0.42397749423980713,\n",
       " -0.2530551552772522,\n",
       " -0.3397808372974396,\n",
       " 0.44669467210769653,\n",
       " -0.4161216914653778,\n",
       " -0.5866578817367554,\n",
       " 1.6285502910614014,\n",
       " 0.3387530446052551,\n",
       " 0.49256259202957153,\n",
       " -0.17371591925621033,\n",
       " -0.3878786265850067,\n",
       " -1.6410624980926514,\n",
       " -0.18864741921424866,\n",
       " -0.1933067888021469,\n",
       " 0.42516854405403137,\n",
       " 3.0729329586029053,\n",
       " -0.33034655451774597,\n",
       " -0.4795575439929962,\n",
       " 0.5702086687088013,\n",
       " 0.02830212190747261,\n",
       " -0.26196521520614624,\n",
       " 0.3754180669784546,\n",
       " -0.2619589567184448,\n",
       " 0.17168381810188293,\n",
       " -0.6922481060028076,\n",
       " 0.9063654541969299,\n",
       " 0.2135864794254303,\n",
       " -0.42348435521125793,\n",
       " 0.367289662361145,\n",
       " 0.1338360458612442,\n",
       " -0.2871904969215393,\n",
       " -0.09794259071350098,\n",
       " 0.3032161593437195,\n",
       " -0.3353010416030884,\n",
       " -2.4239962100982666,\n",
       " 0.6417145133018494,\n",
       " 0.4156786799430847,\n",
       " -0.48703357577323914,\n",
       " 0.5287877321243286,\n",
       " -0.14844132959842682,\n",
       " 0.6460654735565186,\n",
       " -0.1959683895111084,\n",
       " 0.08082636445760727,\n",
       " 0.09762707352638245,\n",
       " 0.6055977940559387,\n",
       " 1.635400652885437,\n",
       " 0.4154178500175476,\n",
       " 0.2554471790790558,\n",
       " -0.08127368241548538,\n",
       " 0.622374951839447,\n",
       " 0.5016567707061768,\n",
       " 0.43651822209358215,\n",
       " 2.5619001388549805,\n",
       " -0.47626379132270813,\n",
       " 1.3404649496078491,\n",
       " 0.2727453410625458,\n",
       " 0.2281535267829895,\n",
       " -0.15654751658439636,\n",
       " -1.1326764822006226,\n",
       " -0.4213760197162628,\n",
       " -0.3746059536933899,\n",
       " -0.18174904584884644,\n",
       " -0.3587997257709503,\n",
       " 0.5513988733291626,\n",
       " -0.5566838383674622,\n",
       " -0.19403329491615295,\n",
       " 0.424070805311203,\n",
       " -0.5782437324523926,\n",
       " -0.6270618438720703,\n",
       " 0.33616989850997925,\n",
       " 0.11583197861909866,\n",
       " -0.004875396378338337,\n",
       " 0.18971925973892212,\n",
       " 0.37394100427627563,\n",
       " 0.4455319941043854,\n",
       " 0.3330942392349243,\n",
       " 0.3889234960079193,\n",
       " -0.15098661184310913,\n",
       " 0.46980106830596924,\n",
       " 0.5136247277259827,\n",
       " -0.4794141948223114,\n",
       " -0.1533508151769638,\n",
       " -0.03883320838212967,\n",
       " 0.3655506372451782,\n",
       " -0.320494681596756,\n",
       " -0.4924055337905884,\n",
       " -0.5492672324180603,\n",
       " 1.7998205423355103,\n",
       " 0.30644819140434265,\n",
       " -0.578447163105011,\n",
       " -0.03576227277517319,\n",
       " -1.4744921922683716,\n",
       " 0.5213053226470947,\n",
       " -0.634514570236206,\n",
       " 0.4257337152957916,\n",
       " -0.2575465738773346,\n",
       " 0.0805053785443306,\n",
       " 0.04068593680858612,\n",
       " -0.700934648513794,\n",
       " 0.6936213374137878,\n",
       " 0.014353945851325989,\n",
       " -0.13861145079135895,\n",
       " 0.29810476303100586,\n",
       " 0.6789795756340027,\n",
       " -0.45949888229370117,\n",
       " -0.00662991451099515,\n",
       " 0.5143455266952515,\n",
       " 0.2970440685749054,\n",
       " -0.9955425262451172,\n",
       " -0.6845551133155823,\n",
       " -0.8337588906288147,\n",
       " -0.35679054260253906,\n",
       " 0.2580830156803131,\n",
       " 0.5966396927833557,\n",
       " 0.2361251711845398,\n",
       " -1.3348686695098877,\n",
       " -0.6591356992721558,\n",
       " -0.3016987144947052,\n",
       " -0.32294052839279175,\n",
       " 0.03342418745160103,\n",
       " 0.5429023504257202,\n",
       " 0.3874950408935547,\n",
       " 1.7555770874023438,\n",
       " 0.9212824106216431,\n",
       " 0.15505340695381165,\n",
       " -0.015752822160720825,\n",
       " -0.3658458888530731,\n",
       " -0.08218860626220703,\n",
       " 1.1291346549987793,\n",
       " -0.657561719417572,\n",
       " 0.3338375687599182,\n",
       " -0.6837068796157837,\n",
       " -0.4569554030895233,\n",
       " 0.3747475743293762,\n",
       " -0.6734482645988464,\n",
       " -0.5772234797477722,\n",
       " -0.037690870463848114,\n",
       " 0.2594049572944641,\n",
       " 0.9038822650909424,\n",
       " 0.4652997553348541,\n",
       " 1.577831506729126,\n",
       " -0.3221594989299774,\n",
       " 0.34693241119384766,\n",
       " -0.25934016704559326,\n",
       " -0.8759908080101013,\n",
       " 0.20383985340595245,\n",
       " -0.2920086085796356,\n",
       " -0.45417600870132446,\n",
       " -1.4978688955307007,\n",
       " 0.1398676335811615,\n",
       " 0.5048319697380066,\n",
       " 0.15653690695762634,\n",
       " 0.5318850874900818,\n",
       " -0.741768479347229,\n",
       " 0.37362411618232727,\n",
       " 0.15861837565898895,\n",
       " -0.1711331307888031,\n",
       " -0.8400149941444397,\n",
       " 0.6229197382926941,\n",
       " -0.4832639694213867,\n",
       " 0.6561854481697083,\n",
       " 0.007043891586363316,\n",
       " -0.1294262409210205,\n",
       " -0.19099737703800201,\n",
       " -0.03924539312720299,\n",
       " 0.22609318792819977,\n",
       " 1.541724443435669,\n",
       " -0.4748690724372864,\n",
       " -0.018853817135095596,\n",
       " 0.6355984210968018,\n",
       " 0.2031642496585846,\n",
       " -0.07511625438928604,\n",
       " 0.6481797099113464,\n",
       " 0.9533924460411072,\n",
       " -0.29975512623786926,\n",
       " -0.23765279352664948,\n",
       " 0.2432108223438263,\n",
       " -0.3264476954936981,\n",
       " -0.2246965616941452,\n",
       " -0.15227699279785156,\n",
       " -0.05674823746085167,\n",
       " 0.7273123860359192,\n",
       " -0.2697563171386719,\n",
       " 0.3804919123649597,\n",
       " 0.7492501735687256,\n",
       " 1.3192986249923706,\n",
       " 0.6480050683021545,\n",
       " -0.3051081895828247,\n",
       " -0.7209682464599609,\n",
       " -0.047724898904561996,\n",
       " 0.42651036381721497,\n",
       " 0.26790088415145874,\n",
       " -0.08381231129169464,\n",
       " -0.37226390838623047,\n",
       " 0.1502007395029068,\n",
       " -0.4710482060909271,\n",
       " -1.0044827461242676,\n",
       " -0.8069597482681274,\n",
       " 0.6834436655044556,\n",
       " 0.18216048181056976,\n",
       " -0.12962797284126282,\n",
       " -0.1553250253200531,\n",
       " -0.5746659636497498,\n",
       " 0.6957781910896301,\n",
       " -0.36738353967666626,\n",
       " 0.7029780745506287,\n",
       " 0.6104781031608582,\n",
       " -0.3372603952884674,\n",
       " 0.13671875,\n",
       " 1.2471307516098022,\n",
       " 0.2983221709728241,\n",
       " -0.7049144506454468,\n",
       " 0.3550170063972473,\n",
       " -1.4111273288726807,\n",
       " 0.18553780019283295,\n",
       " -0.4200933575630188,\n",
       " 0.692803680896759,\n",
       " 0.2646101713180542,\n",
       " 0.7089402079582214,\n",
       " -0.2285611629486084,\n",
       " 0.26720720529556274,\n",
       " -0.21028229594230652,\n",
       " 0.5326464772224426,\n",
       " -0.15517687797546387,\n",
       " -0.4115431010723114,\n",
       " 0.49935781955718994,\n",
       " -0.2137102335691452,\n",
       " 0.31178271770477295,\n",
       " 0.20281721651554108,\n",
       " -0.9404743909835815,\n",
       " -0.4970517158508301,\n",
       " 0.5404319167137146]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_code_embeddings(code_data, model_name):\n",
    "    \"\"\"\n",
    "    加载代码，生成嵌入\n",
    "    \"\"\"\n",
    "    \n",
    "    # 加载预训练模型\n",
    "    print(f\"Loading embedding model: {model_name}...\")\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    # 生成嵌入\n",
    "    print(\"Generating embeddings...\")\n",
    "    embeddings = model.encode(code_data, show_progress_bar=True).tolist()\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d56a6be-5f28-4a23-bf12-e1708c4f032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型整体架构(必须导入，不必修改)\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads=4, dropout=0.1):\n",
    "        super(CrossAttention, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=num_heads, dropout=dropout)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, query, key, value):\n",
    "        # query, key, value: [batch_size, seq_len, embed_dim]\n",
    "        attn_output, _ = self.attention(query, key, value)\n",
    "        return self.norm(attn_output + query)  # Add & Norm\n",
    "        \n",
    "class AblationModelWithWeights(nn.Module):\n",
    "    def __init__(self, \n",
    "                 code_input_dim, \n",
    "                 tabular_input_dim, \n",
    "                 gcn_hidden_dim, \n",
    "                 gcn_output_dim, \n",
    "                 embed_dim=32,\n",
    "                 use_code=True, \n",
    "                 use_tabular=True, \n",
    "                 use_graph=True):\n",
    "        super(AblationModelWithWeights, self).__init__()\n",
    "\n",
    "        # 是否使用各分支\n",
    "        self.use_code = use_code\n",
    "        self.use_tabular = use_tabular\n",
    "        self.use_graph = use_graph\n",
    "\n",
    "        # Code Embedding 分支\n",
    "        if self.use_code:\n",
    "            self.code_branch = nn.Sequential(\n",
    "                nn.Linear(code_input_dim, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(128, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, embed_dim)\n",
    "            )\n",
    "\n",
    "        # Tabular 数据分支\n",
    "        if self.use_tabular:\n",
    "            self.tabular_branch = nn.Sequential(\n",
    "                nn.Linear(tabular_input_dim, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(64, embed_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "\n",
    "        # GCN 分支\n",
    "        if self.use_graph:\n",
    "            self.gcn1 = GCNConv(32, gcn_hidden_dim)\n",
    "            self.bn1 = nn.BatchNorm1d(gcn_hidden_dim)\n",
    "            self.gcn2 = GCNConv(gcn_hidden_dim, gcn_output_dim)\n",
    "            self.bn2 = nn.BatchNorm1d(gcn_output_dim)\n",
    "\n",
    "        # 交叉注意力模块\n",
    "        self.cross_attention_1 = CrossAttention(embed_dim)\n",
    "        self.cross_attention_2 = CrossAttention(embed_dim)\n",
    "\n",
    "        # 模态权重参数（可学习）\n",
    "        self.modal_weights = nn.Parameter(torch.ones(3))  # 初始化为 1，表示每个模态的初始权重相等\n",
    "\n",
    "        # 融合层\n",
    "        self.fusion_layer = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                (embed_dim if self.use_code else 0) +\n",
    "                (embed_dim if self.use_tabular else 0) +\n",
    "                (gcn_output_dim if self.use_graph else 0), \n",
    "                128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 4)  # 输出4个标签\n",
    "        )\n",
    "\n",
    "    def forward(self, code_data, tabular_data, graph_data):\n",
    "        fusion_input = []\n",
    "        modal_contributions = []\n",
    "\n",
    "        # Code Embedding 分支\n",
    "        if self.use_code:\n",
    "            code_out = self.code_branch(code_data)  # [batch_size, embed_dim]\n",
    "            fusion_input.append(code_out)\n",
    "            modal_contributions.append(self.modal_weights[0])  # 添加 code 模态的权重\n",
    "\n",
    "        # Tabular 数据分支\n",
    "        if self.use_tabular:\n",
    "            tabular_out = self.tabular_branch(tabular_data)  # [batch_size, embed_dim]\n",
    "            fusion_input.append(tabular_out)\n",
    "            modal_contributions.append(self.modal_weights[1])  # 添加 tabular 模态的权重\n",
    "\n",
    "        # GCN 分支\n",
    "        if self.use_graph:\n",
    "            x, edge_index, batch = graph_data.x, graph_data.edge_index, graph_data.batch\n",
    "            x = F.relu(self.bn1(self.gcn1(x, edge_index)))\n",
    "            x = F.relu(self.bn2(self.gcn2(x, edge_index)))\n",
    "            x = global_mean_pool(x, batch)  # [batch_size, gcn_output_dim]\n",
    "            fusion_input.append(x)\n",
    "            modal_contributions.append(self.modal_weights[2])  # 添加 graph 模态的权重\n",
    "\n",
    "        # 如果没有启用任何分支，直接抛出错误\n",
    "        if len(fusion_input) == 0:\n",
    "            raise ValueError(\"At least one of 'use_code', 'use_tabular', or 'use_graph' must be True.\")\n",
    "\n",
    "        # 对模态权重进行 softmax 标准化\n",
    "        modal_contributions = F.softmax(torch.stack(modal_contributions), dim=0)  # [num_modalities]\n",
    "        \n",
    "        # 对每个模态的输出乘以对应的权重\n",
    "        weighted_fusion_input = [\n",
    "            modal_contributions[i] * fusion_input[i] for i in range(len(fusion_input))\n",
    "        ]\n",
    "\n",
    "        # 融合\n",
    "        fusion_input = torch.cat(weighted_fusion_input, dim=1)  # 按最后一维拼接\n",
    "        out = self.fusion_layer(fusion_input)  # [batch_size, 4]\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc604d1a-23ef-4f6b-a830-7197b1a9e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_by_category_with_embeddings(config, model_path, code_embeddings, device):\n",
    "    # 初始化模型\n",
    "    model = AblationModelWithWeights(\n",
    "        code_input_dim=768,  # 输入为预先生成的嵌入维度\n",
    "        tabular_input_dim=16,\n",
    "        gcn_hidden_dim=32,\n",
    "        gcn_output_dim=16,\n",
    "        embed_dim=32,\n",
    "        **config\n",
    "    ).to(device)\n",
    "\n",
    "    # 加载模型参数\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # 模态处理逻辑\n",
    "    with torch.no_grad():\n",
    "        # 直接处理整个 code_embeddings\n",
    "        code_data = torch.tensor(code_embeddings).unsqueeze(0).to(device)  # 生成 [1, 768] 的张量\n",
    "        tabular_data = torch.zeros(code_data.size(0), 16).to(device)  # 填充 tabular 数据为 (batch_size, 16)\n",
    "        graph_data = Data(\n",
    "            x=torch.zeros(code_data.size(0), 32).to(device),  # 填充节点特征为 32\n",
    "            edge_index=torch.zeros(2, code_data.size(0)).to(device).long(),  # 填充边索引\n",
    "            batch=torch.zeros(code_data.size(0), dtype=torch.long).to(device)  # 填充批次索引\n",
    "        )\n",
    "        # 模型推理\n",
    "        outputs = model(code_data, tabular_data, graph_data)\n",
    "    return outputs.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e775de59-bb7f-45b9-bd55-e4aea81ba00d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 1:\n",
      "  AMAT: 0.0028\n",
      "  Time: 0.0330\n",
      "  L1 Hit Rate: 0.6216\n",
      "  L2 Hit Rate: -0.0050\n",
      "\n",
      "Prediction 2:\n",
      "  AMAT: 0.0004\n",
      "  Time: 0.0391\n",
      "  L1 Hit Rate: 0.6577\n",
      "  L2 Hit Rate: 0.0046\n",
      "\n",
      "Prediction 3:\n",
      "  AMAT: 0.0660\n",
      "  Time: -0.0055\n",
      "  L1 Hit Rate: 0.9032\n",
      "  L2 Hit Rate: 1.2431\n",
      "\n",
      "Prediction 4:\n",
      "  AMAT: 0.0081\n",
      "  Time: 0.0345\n",
      "  L1 Hit Rate: 0.6241\n",
      "  L2 Hit Rate: 0.0013\n",
      "\n",
      "Prediction 5:\n",
      "  AMAT: 0.0002\n",
      "  Time: 0.0402\n",
      "  L1 Hit Rate: 0.6039\n",
      "  L2 Hit Rate: 0.0391\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 训练设备部署\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "'''\n",
    "codebert-base需要安装\n",
    "\n",
    "1、安装huggingface-cli（使用镜像）\n",
    "pip install 'huggingface_hub[cli]' --index-url=https://mirrors.aliyun.com/pypi/simple\n",
    "\n",
    "2、下载codebert-base模型\n",
    "huggingface-cli download microsoft/codebert-base --local-dir 预存储本地位置\n",
    "\n",
    "'''\n",
    "\n",
    "# 接收输入的代码\n",
    "source_code= \"__global__ void mm2_kernel1(int ni, int nj, int nk, int nl, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE *tmp, DATA_TYPE *A, DATA_TYPE *B)\\n{\\n\\tint j = blockIdx.x * blockDim.x + threadIdx.x;\\n\\tint i = blockIdx.y * blockDim.y + threadIdx.y;\\n\\n\\tif ((i < _PB_NI) && (j < _PB_NJ))\\n\\t{ \\n\\t\\ttmp[i * NJ + j] = 0;\\n\\t\\tint k;\\n\\t\\tfor (k = 0; k < _PB_NK; k++)\\n\\t\\t{\\n\\t\\t\\ttmp[i * NJ + j] += alpha * A[i * NK + k] * B[k * NJ + j];\\n\\t\\t}\\n\\t}\\n}\"\n",
    "\n",
    "# 替换为codebert-base本地存储位置\n",
    "embedding_model = \"/home/pm/codebert-base\"\n",
    "\n",
    "# 输入代码，生成嵌入\n",
    "code_embedding = generate_code_embeddings(source_code, embedding_model)\n",
    "\n",
    "# 存储所有预测结果\n",
    "all_predictions = []\n",
    "\n",
    "# 设置模态\n",
    "configs = [\n",
    "    {'use_code': True, 'use_tabular': True, 'use_graph': True},  # 全部启用（Baseline）\n",
    "    {'use_code': False, 'use_tabular': True, 'use_graph': True},  # 去掉 Code 分支\n",
    "    {'use_code': True, 'use_tabular': False, 'use_graph': True},  # 去掉 Tabular 分支\n",
    "    {'use_code': True, 'use_tabular': True, 'use_graph': False},  # 去掉 Graph 分支\n",
    "    {'use_code': True, 'use_tabular': False, 'use_graph': False},  # 只有code 分支\n",
    "]\n",
    "for config in configs:\n",
    "    # 模型加载\n",
    "    model_load_path = f\"model/model_{str(config)}.pth\"\n",
    "    # 预测\n",
    "    prediction=test_model_by_category_with_embeddings(config, model_load_path, code_embedding, device)\n",
    "    all_predictions.append(prediction)\n",
    "    \n",
    "# 参数名称\n",
    "parameter_names = [\"AMAT\", \"Time\", \"L1 Hit Rate\", \"L2 Hit Rate\"]\n",
    "\n",
    "# 提取并打印每个预测的结果\n",
    "for idx, prediction in enumerate(all_predictions):\n",
    "    print(f\"Prediction {idx + 1}:\")\n",
    "    for param_idx, param_name in enumerate(parameter_names):\n",
    "        print(f\"  {param_name}: {prediction[0][param_idx]:.4f}\")\n",
    "    print()  # 空行分隔每个预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1c3b8d-0160-4be3-b571-3cb049305327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
